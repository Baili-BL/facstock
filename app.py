#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¸ƒæ—å¸¦æ”¶ç¼©ç­–ç•¥ - Flask Web åº”ç”¨
"""

import sys
# ç¦ç”¨è¾“å‡ºç¼“å†²ï¼Œç¡®ä¿ print ç«‹å³æ˜¾ç¤º
sys.stdout.reconfigure(line_buffering=True)

from flask import Flask, render_template, jsonify, request
from bollinger_squeeze_strategy import BollingerSqueezeStrategy
from utils.retry import retry_request
import pandas as pd
from datetime import datetime, timedelta
import threading
import time
import random
import logging

# å¯¼å…¥æ•°æ®åº“æ¨¡å—
import database as db

# å¯¼å…¥ AI æœåŠ¡æ¨¡å—
from ai_service import get_ai_service

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = Flask(__name__)

# å…¨å±€å˜é‡å­˜å‚¨å½“å‰æ‰«æçŠ¶æ€ï¼ˆç”¨äºå®æ—¶è¿›åº¦æŸ¥è¯¢ï¼‰
scan_status = {
    'is_scanning': False,
    'scan_id': None,
    'progress': 0,
    'current_sector': '',
    'error': None,
    'cancelled': False
}


@app.route('/')
def index():
    """ä¸»é¡µ"""
    return render_template('index.html')


@app.route('/api/hot-sectors')
def get_hot_sectors():
    """
    è·å–çƒ­ç‚¹æ¿å—åˆ—è¡¨ï¼ˆåŒèŠ±é¡ºæ•°æ®æºï¼‰
    
    è¿”å›å½“å‰Aè‚¡å¸‚åœºæ¶¨å¹…å‰20çš„çƒ­ç‚¹æ¿å—ä¿¡æ¯ã€‚
    
    Query Parameters:
        limit (int, optional): è¿”å›æ•°é‡é™åˆ¶ï¼Œé»˜è®¤20ï¼Œæœ€å¤§50
        
    Returns:
        JSON: {
            success: bool,
            data: [{name, change, leader, leader_change}, ...],
            error: str (ä»…å¤±è´¥æ—¶)
        }
    """
    try:
        from utils.ths_crawler import get_ths_industry_list
        
        # è·å–å¹¶éªŒè¯ limit å‚æ•°
        limit = request.args.get('limit', 20, type=int)
        limit = max(1, min(50, limit))  # é™åˆ¶åœ¨ 1-50 ä¹‹é—´
        
        logger.info(f"è·å–çƒ­ç‚¹æ¿å—åˆ—è¡¨(THS)ï¼Œlimit={limit}")
        
        df = retry_request(get_ths_industry_list, max_retries=3, delay=1.0)
        
        if df is None or len(df) == 0:
            logger.warning("çƒ­ç‚¹æ¿å—æ•°æ®ä¸ºç©º")
            return jsonify({'success': False, 'error': 'æ— æ³•è·å–æ•°æ®'})
        
        # æ„å»ºè¿”å›æ•°æ®ï¼ˆå·²æŒ‰æ¶¨è·Œå¹…æ’åºï¼‰
        sectors = []
        for _, row in df.head(limit).iterrows():
            sectors.append({
                'name': row['æ¿å—'],
                'change': round(float(row['æ¶¨è·Œå¹…']), 2),
                'leader': row.get('é¢†æ¶¨è‚¡', ''),
                'leader_change': round(float(row.get('é¢†æ¶¨è‚¡-æ¶¨è·Œå¹…', 0)), 2)
            })
        
        logger.info(f"æˆåŠŸè·å– {len(sectors)} ä¸ªçƒ­ç‚¹æ¿å—")
        return jsonify({'success': True, 'data': sectors})
        
    except Exception as e:
        logger.error(f"è·å–çƒ­ç‚¹æ¿å—å¤±è´¥: {e}")
        return jsonify({'success': False, 'error': str(e)})


@app.route('/api/scan/start', methods=['POST'])
def start_scan():
    """
    å¼€å§‹æ‰«æä»»åŠ¡
    
    å¯åŠ¨åå°æ‰«æçº¿ç¨‹ï¼Œæ‰«æçƒ­ç‚¹æ¿å—ä¸­ç¬¦åˆå¸ƒæ—å¸¦æ”¶ç¼©æ¡ä»¶çš„è‚¡ç¥¨ã€‚
    
    Request Body (JSON):
        sectors (int, optional): æ‰«ææ¿å—æ•°é‡ï¼Œé»˜è®¤5ï¼ŒèŒƒå›´1-20
        min_days (int, optional): æœ€å°æ”¶ç¼©å¤©æ•°ï¼Œé»˜è®¤3ï¼ŒèŒƒå›´1-10
        period (int, optional): å¸ƒæ—å¸¦å‘¨æœŸï¼Œé»˜è®¤20ï¼ŒèŒƒå›´10-60
        
    Returns:
        JSON: {
            success: bool,
            message: str,
            scan_id: int (æˆåŠŸæ—¶)
        }
    """
    global scan_status
    
    if scan_status['is_scanning']:
        return jsonify({'success': False, 'error': 'æ‰«ææ­£åœ¨è¿›è¡Œä¸­'})
    
    data = request.json or {}
    
    # å‚æ•°éªŒè¯å’Œé»˜è®¤å€¼
    top_sectors = data.get('sectors', 5)
    min_days = data.get('min_days', 3)
    period = data.get('period', 20)
    
    # å‚æ•°èŒƒå›´éªŒè¯
    top_sectors = max(1, min(20, int(top_sectors)))
    min_days = max(1, min(10, int(min_days)))
    period = max(10, min(60, int(period)))
    
    logger.info(f"å¼€å§‹æ‰«æ: sectors={top_sectors}, min_days={min_days}, period={period}")
    
    # åˆ›å»ºæ•°æ®åº“è®°å½•
    params = {
        'sectors': top_sectors,
        'min_days': min_days,
        'period': period
    }
    scan_id = db.create_scan_record(params)
    
    # é‡ç½®çŠ¶æ€
    scan_status = {
        'is_scanning': True,
        'scan_id': scan_id,
        'progress': 0,
        'current_sector': 'å‡†å¤‡ä¸­...',
        'error': None,
        'cancelled': False
    }
    
    # åœ¨åå°çº¿ç¨‹æ‰§è¡Œæ‰«æ
    import sys
    print(f"ğŸš€ å¯åŠ¨æ‰«æçº¿ç¨‹: scan_id={scan_id}", flush=True)
    sys.stdout.flush()
    thread = threading.Thread(
        target=run_scan,
        args=(scan_id, top_sectors, min_days, period)
    )
    thread.daemon = True
    thread.start()
    print(f"âœ… æ‰«æçº¿ç¨‹å·²å¯åŠ¨", flush=True)
    sys.stdout.flush()
    
    return jsonify({'success': True, 'message': 'æ‰«æå·²å¼€å§‹', 'scan_id': scan_id})


@app.route('/api/scan/cancel', methods=['POST'])
def cancel_scan():
    """å–æ¶ˆå½“å‰æ‰«æ"""
    global scan_status
    
    if not scan_status['is_scanning']:
        return jsonify({'success': False, 'error': 'æ²¡æœ‰æ­£åœ¨è¿›è¡Œçš„æ‰«æ'})
    
    scan_status['cancelled'] = True
    scan_status['current_sector'] = 'æ­£åœ¨å–æ¶ˆ...'
    
    return jsonify({'success': True, 'message': 'æ­£åœ¨å–æ¶ˆæ‰«æ'})


def analyze_single_stock(strategy, stock_info, precache_kline=True):
    """åˆ†æå•åªè‚¡ç¥¨ï¼ˆç”¨äºå¹¶å‘ï¼‰
    
    Args:
        strategy: ç­–ç•¥å®ä¾‹
        stock_info: è‚¡ç¥¨ä¿¡æ¯å­—å…¸
        precache_kline: æ˜¯å¦é¢„ç¼“å­˜Kçº¿æ•°æ®ï¼ˆé»˜è®¤Trueï¼‰
    """
    # éšæœºå»¶è¿Ÿ 0.05-0.15 ç§’ï¼Œé”™å¼€è¯·æ±‚æ—¶é—´é¿å…APIé™æµ
    time.sleep(random.uniform(0.05, 0.15))
    
    try:
        code = stock_info['code']
        name = stock_info['name']
        result = strategy.analyze_stock(code, name, return_df=precache_kline)
        
        if result:
            # å¦‚æœè¿”å›äº†dfï¼Œæå–å¹¶ç¼“å­˜Kçº¿æ•°æ®
            df = None
            if isinstance(result, tuple):
                result, df = result
            
            # æ·»åŠ æ¿å—ä¿¡æ¯
            result['sector_name'] = stock_info.get('sector_name', '')
            result['sector_change'] = stock_info.get('sector_change', 0)
            
            # æ·»åŠ æ ‡ç­¾ä¿¡æ¯
            result['is_leader'] = stock_info.get('is_leader', False)
            result['leader_rank'] = stock_info.get('leader_rank', 0)
            result['market_cap'] = stock_info.get('market_cap', 0)
            
            # ç”Ÿæˆæ ‡ç­¾åˆ—è¡¨ï¼ˆä¸å«emojiï¼Œç”±å‰ç«¯æ·»åŠ å›¾æ ‡ï¼‰
            tags = []
            
            # è¯„çº§æ ‡ç­¾ (æœ€é‡è¦)
            grade = result.get('grade', 'C')
            if grade == 'S':
                tags.append("Sçº§")
            elif grade == 'A':
                tags.append("Açº§")
            
            # ä¸­å†›æ ‡ç­¾
            if result['is_leader']:
                tags.append(f"ä¸­å†›#{result['leader_rank']}")
            
            # CMF èµ„é‡‘æµæ ‡ç­¾
            if result.get('cmf_strong_bullish'):
                tags.append("å¼ºåŠ¿æµå…¥")
            elif result.get('cmf_bullish') and result.get('cmf_rising'):
                tags.append("èµ„é‡‘æµå…¥")
            elif result.get('cmf_bullish'):
                tags.append("èµ„é‡‘å‡€æµå…¥")
            
            # RSV æ ‡ç­¾
            if result.get('rsv_recovering'):
                tags.append("è¶…å–å›å‡")
            elif result.get('rsv_golden'):
                rsv_val = result.get('rsv', 50)
                if rsv_val >= 65:
                    tags.append("RSVå¼ºåŠ¿")
                else:
                    tags.append("RSVå¥åº·")
            
            # è¶‹åŠ¿æ ‡ç­¾
            if result.get('ma_full_bullish'):
                tags.append("å¤šå¤´æ’åˆ—")
            elif result.get('ma_bullish'):
                tags.append("çŸ­å¤š")
            
            # MACDæ ‡ç­¾
            if result.get('macd_golden') and result.get('macd_hist_positive'):
                tags.append("MACDå¼ºåŠ¿")
            elif result.get('macd_golden'):
                tags.append("MACDé‡‘å‰")
            
            # é‡èƒ½æ ‡ç­¾
            if result.get('is_volume_price_up'):
                tags.append("é‡ä»·é½å‡")
            elif result.get('is_volume_up'):
                tags.append("æ”¾é‡")
            
            # æ³¢åŠ¨ç‡æ ‡ç­¾
            if result.get('low_volatility'):
                tags.append("ä½æ³¢è“„åŠ¿")
            
            # äººæ°”æ ‡ç­¾ï¼ˆæ ¹æ®æ¢æ‰‹ç‡ï¼‰
            turnover = result.get('turnover', 0)
            if 3 <= turnover <= 10:
                tags.append("äººæ°”æ—º")
            elif turnover > 10:
                tags.append("è¶…äººæ°”")
            elif 1 <= turnover < 3:
                tags.append("æœ‰å…³æ³¨")
            
            # å…¶ä»–æ ‡ç­¾
            if result.get('pct_change', 0) >= 5:
                tags.append("å…ˆé”‹")
            
            result['tags'] = tags
            
            # å¦‚æœæœ‰dfï¼Œé¢„ç¼“å­˜Kçº¿æ•°æ®
            if df is not None and precache_kline:
                try:
                    kline_data = prepare_kline_data(df)
                    if kline_data:
                        db.save_kline_cache(code, kline_data)
                except Exception as e:
                    print(f"[WARN] é¢„ç¼“å­˜Kçº¿æ•°æ®å¤±è´¥ {code}: {e}")
            
            return result
    except Exception:
        pass
    return None


def prepare_kline_data(df):
    """ä»DataFrameå‡†å¤‡Kçº¿æ•°æ®ï¼ˆä¾›ç¼“å­˜ä½¿ç”¨ï¼‰"""
    try:
        # ç§»é™¤åŒ…å«NaNçš„è¡Œ
        df = df.dropna(subset=['bb_upper', 'bb_lower', 'bb_middle', 'width_ma_short', 'width_ma_long'])
        
        # å–æœ€è¿‘60å¤©æ•°æ®
        df = df.tail(60)
        
        if len(df) == 0:
            return None
        
        # è½¬æ¢ä¸ºåˆ—è¡¨ï¼Œå¤„ç†å¯èƒ½çš„NaNå€¼
        def safe_list(series):
            return [None if pd.isna(x) else float(x) for x in series]
        
        # æ—¥æœŸè½¬å­—ç¬¦ä¸²
        def date_to_str(d):
            if hasattr(d, 'strftime'):
                return d.strftime('%Y-%m-%d')
            return str(d)
        
        # ç”Ÿæˆèœ¡çƒ›å›¾æ•°æ® (Lightweight Chartsæ ¼å¼)
        candles = []
        for _, row in df.iterrows():
            candles.append({
                'time': date_to_str(row['date']),
                'open': float(row['open']) if pd.notna(row['open']) else None,
                'high': float(row['high']) if pd.notna(row['high']) else None,
                'low': float(row['low']) if pd.notna(row['low']) else None,
                'close': float(row['close']) if pd.notna(row['close']) else None,
            })
        
        # ç”Ÿæˆæˆäº¤é‡æ•°æ®ï¼ˆçº¢æ¶¨ç»¿è·Œï¼Œä¸èœ¡çƒ›å›¾ä¸€è‡´ï¼‰
        volume_data = []
        for _, row in df.iterrows():
            color = '#ef5350' if row['close'] >= row['open'] else '#26a69a'
            volume_data.append({
                'time': date_to_str(row['date']),
                'value': float(row['volume']) if pd.notna(row['volume']) else 0,
                'color': color
            })
        
        # å¸ƒæ—å¸¦æ•°æ®
        bb_upper_data = [{'time': date_to_str(row['date']), 'value': float(row['bb_upper'])} for _, row in df.iterrows() if pd.notna(row['bb_upper'])]
        bb_middle_data = [{'time': date_to_str(row['date']), 'value': float(row['bb_middle'])} for _, row in df.iterrows() if pd.notna(row['bb_middle'])]
        bb_lower_data = [{'time': date_to_str(row['date']), 'value': float(row['bb_lower'])} for _, row in df.iterrows() if pd.notna(row['bb_lower'])]
        
        # CMF æ•°æ®
        cmf_data = safe_list(df['cmf']) if 'cmf' in df.columns else []
        
        # æ¶¨è·Œå¹…æ•°æ®
        pct_change_data = safe_list(df['pct_change']) if 'pct_change' in df.columns else []
        
        # æœ€æ–°ä»·æ ¼ä¿¡æ¯
        latest = df.iloc[-1] if len(df) > 0 else None
        latest_info = None
        if latest is not None:
            latest_info = {
                'close': float(latest['close']) if pd.notna(latest['close']) else 0,
                'pct_change': float(latest['pct_change']) if pd.notna(latest['pct_change']) else 0,
                'date': date_to_str(latest['date']),
            }
        
        return {
            'candles': candles,
            'volumes': volume_data,
            'bb_upper': bb_upper_data,
            'bb_middle': bb_middle_data,
            'bb_lower': bb_lower_data,
            'bb_width': safe_list(df['bb_width_pct']),
            'width_ma5': safe_list(df['width_ma_short']),
            'width_ma10': safe_list(df['width_ma_long']),
            'cmf': cmf_data,
            'pct_change': pct_change_data,
            'latest': latest_info,
            'dates': df['date'].astype(str).tolist(),
        }
    except Exception as e:
        print(f"[ERROR] prepare_kline_data å¤±è´¥: {e}")
        return None


# ==================== å¹¶å‘æ§åˆ¶å·¥å…· ====================
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading

# å…¨å±€ä¿¡å·é‡ï¼Œæ§åˆ¶ API è¯·æ±‚é¢‘ç‡
api_semaphore = threading.Semaphore(3)  # æœ€å¤š3ä¸ªå¹¶å‘è¯·æ±‚


def fetch_with_rate_limit(func, delay=0.3):
    """å¸¦é™æµçš„è¯·æ±‚åŒ…è£…å™¨"""
    with api_semaphore:
        time.sleep(delay)
        return func()


def run_scan(scan_id: int, top_sectors: int, min_days: int, period: int):
    """
    é«˜æ•ˆæ‰«æä»»åŠ¡ï¼ˆä½¿ç”¨åŒèŠ±é¡ºæ•°æ®æºï¼‰
    
    æ•°æ®æµç¨‹ï¼š
    1. åŒèŠ±é¡ºè¡Œä¸šæ’è¡Œ â†’ è·å–çƒ­ç‚¹æ¿å—
    2. åŒèŠ±é¡ºè¡Œä¸šæˆåˆ†è‚¡ â†’ çˆ¬å–æˆåˆ†è‚¡åˆ—è¡¨
    3. æ–°æµªKçº¿æ¥å£ â†’ è·å–Kçº¿æ•°æ®
    4. pandaså‘é‡åŒ– â†’ è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
    
    ä¼˜åŒ–ç­–ç•¥ï¼š
    1. æˆåˆ†è‚¡ç¼“å­˜ï¼šå½“æ—¥æœ‰æ•ˆï¼Œé¿å…é‡å¤çˆ¬å–
    2. Kçº¿ç¼“å­˜ï¼šå½“æ—¥æœ‰æ•ˆï¼Œå¤§å¹…å‡å°‘APIè°ƒç”¨
    3. å¹¶å‘è·å–ï¼š5çº¿ç¨‹å¹¶å‘è·å–Kçº¿
    """
    global scan_status
    
    # å¯¼å…¥åŒèŠ±é¡ºçˆ¬è™«
    from utils.ths_crawler import (
        get_ths_industry_list, 
        fetch_ths_industry_stocks,
        get_stock_kline_sina
    )
    
    try:
        start_time = time.time()
        print(f"ğŸš€ å¼€å§‹æ‰«æ(THSæ•°æ®æº): scan_id={scan_id}, sectors={top_sectors}, min_days={min_days}, period={period}")
        
        strategy = BollingerSqueezeStrategy(
            period=period,
            min_squeeze_days=min_days
        )
        
        # ========== 1. è·å–çƒ­ç‚¹æ¿å—ï¼ˆåŒèŠ±é¡ºï¼‰==========
        print("ğŸ“Š è·å–åŒèŠ±é¡ºçƒ­ç‚¹æ¿å—...")
        scan_status['current_sector'] = 'è·å–çƒ­ç‚¹æ¿å—...'
        
        df = retry_request(get_ths_industry_list, max_retries=3, delay=1.0)
        
        if df is None or len(df) == 0:
            raise Exception('æ— æ³•è·å–çƒ­ç‚¹æ¿å—æ•°æ®')
        
        # å–å‰Nä¸ªçƒ­ç‚¹æ¿å—ï¼ˆDataFrame å·²åŒ…å«ä»£ç ï¼‰
        hot_sectors_list = []
        for _, row in df.head(top_sectors).iterrows():
            hot_sectors_list.append({
                'name': row['æ¿å—'],
                'code': row.get('ä»£ç ', ''),
                'change': round(float(row['æ¶¨è·Œå¹…']), 2),
                'leader': row.get('é¢†æ¶¨è‚¡', ''),
                'leader_change': round(float(row.get('é¢†æ¶¨è‚¡-æ¶¨è·Œå¹…', 0)), 2)
            })
        
        db.save_hot_sectors(scan_id, hot_sectors_list)
        sector_names = [s['name'] for s in hot_sectors_list]
        print(f"âœ… çƒ­ç‚¹æ¿å—: {sector_names}")
        
        # ========== 2. è·å–æˆåˆ†è‚¡ï¼ˆä¼˜å…ˆç¼“å­˜ï¼Œçˆ¬è™«è·å–ï¼‰==========
        print(f"\nğŸ“¥ è·å– {len(hot_sectors_list)} ä¸ªæ¿å—çš„æˆåˆ†è‚¡...")
        scan_status['current_sector'] = 'è·å–æˆåˆ†è‚¡...'
        scan_status['progress'] = 10
        
        # å…ˆæŸ¥ç¼“å­˜
        cached_sectors = db.get_all_sector_stocks_cache(sector_names)
        print(f"  ğŸ“¦ ç¼“å­˜å‘½ä¸­: {len(cached_sectors)}/{len(sector_names)} ä¸ªæ¿å—")
        
        # éœ€è¦çˆ¬å–çš„æ¿å—
        sectors_to_fetch = [s for s in hot_sectors_list if s['name'] not in cached_sectors]
        
        all_sector_stocks = dict(cached_sectors)  # ä»ç¼“å­˜å¼€å§‹
        
        if sectors_to_fetch:
            print(f"  ğŸŒ éœ€è¦çˆ¬å–: {len(sectors_to_fetch)} ä¸ªæ¿å—")
            
            for sector_info in sectors_to_fetch:
                if scan_status.get('cancelled'):
                    break
                    
                sector_name = sector_info['name']
                sector_code = sector_info['code']
                
                if not sector_code:
                    print(f"  âš ï¸ {sector_name}: æ— è¡Œä¸šä»£ç ï¼Œè·³è¿‡")
                    continue
                
                try:
                    print(f"  ğŸ“¥ çˆ¬å– {sector_name}({sector_code})...")
                    stocks = fetch_ths_industry_stocks(sector_code, sector_name)
                    
                    if stocks:
                        # æŒ‰å¸‚å€¼æ’åº
                        stocks.sort(key=lambda x: x.get('market_cap', 0), reverse=True)
                        # ä¿å­˜åˆ°ç¼“å­˜
                        db.save_sector_stocks_cache(sector_name, stocks)
                        all_sector_stocks[sector_name] = stocks
                        print(f"  âœ… {sector_name}: {len(stocks)} åª")
                    else:
                        print(f"  âš ï¸ {sector_name}: æ— æˆåˆ†è‚¡æ•°æ®")
                        
                except Exception as e:
                    print(f"  âŒ {sector_name}: {e}")
        
        # åˆå¹¶å»é‡ï¼Œæ·»åŠ æ¿å—ä¿¡æ¯
        stock_info_map = {}
        for sector_info in hot_sectors_list:
            sector_name = sector_info['name']
            stocks = all_sector_stocks.get(sector_name, [])
            for idx, stock in enumerate(stocks):
                code = stock['code']
                if code not in stock_info_map:
                    stock_info_map[code] = {
                        **stock,
                        'sector_name': sector_name,
                        'sector_change': sector_info['change'],
                        'is_leader': idx < 3,
                        'leader_rank': idx + 1 if idx < 3 else 0,
                    }
        
        stock_codes = list(stock_info_map.keys())
        print(f"ğŸ“Š æˆåˆ†è‚¡: {len(stock_codes)} åªï¼ˆå»é‡åï¼‰\n")
        
        # ========== 3. è·å–Kçº¿æ•°æ®ï¼ˆæ–°æµªæ¥å£ï¼Œä¼˜å…ˆç¼“å­˜ï¼‰==========
        print(f"ğŸ“ˆ è·å–Kçº¿æ•°æ®(æ–°æµªæ¥å£)...")
        scan_status['current_sector'] = 'è·å–Kçº¿æ•°æ®...'
        scan_status['progress'] = 25
        
        # æ‰¹é‡æŸ¥ç¼“å­˜
        cached_klines = db.get_kline_cache_batch(stock_codes)
        print(f"  ğŸ“¦ Kçº¿ç¼“å­˜å‘½ä¸­: {len(cached_klines)}/{len(stock_codes)}")
        
        # éœ€è¦è·å–çš„è‚¡ç¥¨
        codes_to_fetch = [c for c in stock_codes if c not in cached_klines]
        
        kline_data = dict(cached_klines)  # ä»ç¼“å­˜å¼€å§‹
        
        if codes_to_fetch:
            print(f"  ğŸŒ éœ€è¦è·å–: {len(codes_to_fetch)} åªè‚¡ç¥¨Kçº¿")
            
            def fetch_kline(code):
                try:
                    # ä½¿ç”¨æ–°æµªæ¥å£
                    kline_df = get_stock_kline_sina(code, days=120)
                    if kline_df is not None and len(kline_df) >= period + 10:
                        return (code, kline_df)
                    return (code, None)
                except:
                    return (code, None)
            
            # å¹¶å‘è·å–Kçº¿ï¼ˆ5çº¿ç¨‹ï¼‰
            fetched_count = 0
            
            with ThreadPoolExecutor(max_workers=5) as executor:
                futures = []
                for code in codes_to_fetch:
                    future = executor.submit(
                        fetch_with_rate_limit,
                        lambda c=code: fetch_kline(c),
                        delay=0.2
                    )
                    futures.append(future)
                
                for future in as_completed(futures):
                    if scan_status.get('cancelled'):
                        break
                    code, df = future.result()
                    if df is not None:
                        kline_data[code] = df
                        fetched_count += 1
                        
                        # æ›´æ–°è¿›åº¦
                        if fetched_count % 50 == 0:
                            progress = 25 + int(fetched_count / len(codes_to_fetch) * 30)
                            scan_status['progress'] = min(55, progress)
                            print(f"  ğŸ“Š Kçº¿è¿›åº¦: {fetched_count}/{len(codes_to_fetch)}")
            
            print(f"  âœ… Kçº¿è·å–å®Œæˆ: {fetched_count}/{len(codes_to_fetch)}")
        
        # ========== 4. æ‰¹é‡è®¡ç®—æŒ‡æ ‡å¹¶ç­›é€‰ ==========
        print(f"\nğŸ“ˆ è®¡ç®—æŠ€æœ¯æŒ‡æ ‡...")
        scan_status['current_sector'] = 'è®¡ç®—æŒ‡æ ‡...'
        scan_status['progress'] = 60
        
        analyzed_results = []
        total = len(kline_data)
        
        for idx, (code, df) in enumerate(kline_data.items()):
            if scan_status.get('cancelled'):
                print("âš ï¸ æ‰«æå·²å–æ¶ˆ")
                break
            
            if df is None or (isinstance(df, pd.DataFrame) and len(df) < period + 10):
                continue
            
            try:
                # å¦‚æœæ˜¯ç¼“å­˜çš„dictï¼Œè·³è¿‡ï¼ˆå·²ç»æ˜¯åˆ†æç»“æœï¼‰
                if isinstance(df, dict):
                    # ç¼“å­˜çš„æ˜¯åŸå§‹Kçº¿æ•°æ®ï¼Œéœ€è¦è½¬æ¢
                    continue
                
                # è®¡ç®—æŒ‡æ ‡
                df = strategy.calculate_bollinger_bands(df)
                df = strategy.calculate_squeeze_signal(df)
                df = strategy.calculate_volume_signal(df)
                df = strategy.calculate_trend_indicators(df)
                df = strategy.calculate_composite_score(df)
                
                latest = df.iloc[-1]
                
                # ç­›é€‰
                if latest['squeeze_streak'] >= min_days:
                    info = stock_info_map.get(code, {})
                    result = {
                        'code': code,
                        'name': info.get('name', ''),
                        'sector_name': info.get('sector_name', ''),
                        'sector_change': info.get('sector_change', 0),
                        'is_leader': info.get('is_leader', False),
                        'leader_rank': info.get('leader_rank', 0),
                        'market_cap': info.get('market_cap', 0),
                        'close': round(float(latest['close']), 2),
                        'pct_change': round(float(latest.get('pct_change', 0)), 2),
                        'turnover': round(float(latest.get('turnover', 0)), 2),
                        'squeeze_days': int(latest['squeeze_streak']),
                        'total_score': int(latest['total_score']),
                        'grade': latest['grade'],
                        'bb_width_pct': round(float(latest['bb_width_pct']), 2),
                        'ma_bullish': bool(latest.get('ma_bullish', False)),
                        'macd_golden': bool(latest.get('macd_golden', False)),
                        'cmf_bullish': bool(latest.get('cmf_bullish', False)),
                        'is_volume_up': bool(latest.get('is_volume_up', False)),
                        'is_volume_price_up': bool(latest.get('is_volume_price_up', False)),
                        'low_volatility': bool(latest.get('low_volatility', False)),
                    }
                    
                    # ç”Ÿæˆæ ‡ç­¾
                    tags = []
                    if result['grade'] in ['S', 'A']:
                        tags.append(f"{result['grade']}çº§")
                    if result['is_leader']:
                        tags.append(f"ä¸­å†›#{result['leader_rank']}")
                    if result.get('cmf_bullish'):
                        tags.append("èµ„é‡‘æµå…¥")
                    if result.get('is_volume_price_up'):
                        tags.append("é‡ä»·é½å‡")
                    result['tags'] = tags
                    
                    analyzed_results.append(result)
                
                # æ›´æ–°è¿›åº¦
                if (idx + 1) % 100 == 0:
                    progress = 60 + int((idx + 1) / total * 30)
                    scan_status['progress'] = min(90, progress)
                    
            except Exception:
                continue
        
        print(f"ğŸ“ˆ åˆ†æå®Œæˆï¼Œç¬¦åˆæ¡ä»¶: {len(analyzed_results)} åª")
        
        # ========== 5. ä¿å­˜ç»“æœ ==========
        scan_status['current_sector'] = 'ä¿å­˜ç»“æœ...'
        scan_status['progress'] = 95
        
        sector_results = {}
        for r in analyzed_results:
            sector = r.get('sector_name', 'æœªçŸ¥')
            if sector not in sector_results:
                sector_results[sector] = []
            sector_results[sector].append(r)
        
        for sector_name, results in sector_results.items():
            results.sort(key=lambda x: x.get('total_score', 0), reverse=True)
            sector_change = results[0].get('sector_change', 0) if results else 0
            db.save_sector_result(scan_id, sector_name, sector_change, results)
            print(f"  ğŸ’¾ {sector_name}: {len(results)} åª")
        
        elapsed = time.time() - start_time
        scan_status['progress'] = 100
        scan_status['current_sector'] = 'æ‰«æå®Œæˆ'
        db.update_scan_status(scan_id, 'completed')
        print(f"\nâœ… æ‰«æå®Œæˆ! è€—æ—¶: {elapsed:.1f}ç§’")
        
    except Exception as e:
        scan_status['error'] = str(e)
        db.update_scan_status(scan_id, 'error', str(e))
        print(f"âŒ æ‰«æå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
    finally:
        scan_status['is_scanning'] = False


@app.route('/api/scan/status')
def get_scan_status():
    """
    è·å–å½“å‰æ‰«æçŠ¶æ€
    
    è¿”å›å½“å‰æ‰«æä»»åŠ¡çš„å®æ—¶çŠ¶æ€ä¿¡æ¯ã€‚
    
    Returns:
        JSON: {
            is_scanning: bool,      # æ˜¯å¦æ­£åœ¨æ‰«æ
            scan_id: int,           # å½“å‰æ‰«æID
            progress: int,          # è¿›åº¦ç™¾åˆ†æ¯” (0-100)
            current_sector: str,    # å½“å‰æ‰«æçš„æ¿å—
            error: str,             # é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœ‰ï¼‰
            cancelled: bool         # æ˜¯å¦å·²å–æ¶ˆ
        }
    """
    return jsonify({
        'is_scanning': scan_status['is_scanning'],
        'scan_id': scan_status.get('scan_id'),
        'progress': scan_status['progress'],
        'current_sector': scan_status['current_sector'],
        'error': scan_status['error'],
        'cancelled': scan_status.get('cancelled', False)
    })


@app.route('/api/scan/results')
def get_scan_results():
    """
    è·å–æ‰«æç»“æœ
    
    è¿”å›æŒ‡å®šæ‰«ææˆ–æœ€æ–°å®Œæˆæ‰«æçš„ç»“æœæ•°æ®ã€‚
    
    Query Parameters:
        scan_id (int, optional): æŒ‡å®šæ‰«æIDï¼Œä¸ä¼ åˆ™è¿”å›æœ€æ–°å®Œæˆçš„æ‰«æ
        
    Returns:
        JSON: {
            success: bool,
            scan_id: int,
            results: {æ¿å—å: {change: float, stocks: [...]}},
            hot_sectors: [{name, change}, ...],
            last_update: str
        }
    """
    # ä»è¯·æ±‚å‚æ•°è·å– scan_idï¼Œå¦‚æœæ²¡æœ‰åˆ™è·å–æœ€æ–°çš„
    scan_id = request.args.get('scan_id', type=int)
    
    if scan_id:
        scan_detail = db.get_scan_detail(scan_id)
    else:
        scan_detail = db.get_latest_scan()
    
    if not scan_detail:
        return jsonify({
            'success': True,
            'results': {},
            'hot_sectors': [],
            'last_update': None
        })
    
    return jsonify({
        'success': True,
        'scan_id': scan_detail['id'],
        'results': scan_detail.get('results', {}),
        'hot_sectors': scan_detail.get('hot_sectors', []),
        'last_update': scan_detail['scan_time']
    })


@app.route('/api/scan/history')
def get_scan_history():
    """
    è·å–å†å²æ‰«æè®°å½•åˆ—è¡¨
    
    Query Parameters:
        limit (int, optional): è¿”å›æ•°é‡é™åˆ¶ï¼Œé»˜è®¤20
        
    Returns:
        JSON: {success: bool, data: [...]}
    """
    limit = request.args.get('limit', 20, type=int)
    limit = max(1, min(100, limit))  # é™åˆ¶åœ¨ 1-100 ä¹‹é—´
    records = db.get_scan_list(limit=limit)
    return jsonify({
        'success': True,
        'data': records
    })


@app.route('/api/scan/<int:scan_id>', methods=['GET'])
def get_scan_detail(scan_id: int):
    """
    è·å–æŒ‡å®šæ‰«æçš„è¯¦ç»†ç»“æœ
    
    Args:
        scan_id: æ‰«æè®°å½•ID
        
    Returns:
        JSON: {success: bool, data: {...}}
    """
    scan_detail = db.get_scan_detail(scan_id)
    
    if not scan_detail:
        return jsonify({
            'success': False,
            'error': 'æ‰«æè®°å½•ä¸å­˜åœ¨'
        }), 404
    
    return jsonify({
        'success': True,
        'data': scan_detail
    })


@app.route('/api/scan/<int:scan_id>', methods=['DELETE'])
def delete_scan(scan_id: int):
    """åˆ é™¤æŒ‡å®šæ‰«æè®°å½•"""
    # æ£€æŸ¥æ˜¯å¦æ­£åœ¨æ‰«æä¸­
    if scan_status['is_scanning'] and scan_status.get('scan_id') == scan_id:
        return jsonify({
            'success': False,
            'error': 'æ— æ³•åˆ é™¤æ­£åœ¨è¿›è¡Œçš„æ‰«æ'
        }), 400
    
    success = db.delete_scan(scan_id)
    
    if success:
        return jsonify({
            'success': True,
            'message': 'åˆ é™¤æˆåŠŸ'
        })
    else:
        return jsonify({
            'success': False,
            'error': 'æ‰«æè®°å½•ä¸å­˜åœ¨'
        }), 404


@app.route('/api/scan/clear', methods=['DELETE'])
def clear_all_scans():
    """æ¸…ç©ºæ‰€æœ‰æ‰«æè®°å½•"""
    if scan_status['is_scanning']:
        return jsonify({
            'success': False,
            'error': 'æœ‰æ‰«ææ­£åœ¨è¿›è¡Œä¸­ï¼Œè¯·ç¨åå†è¯•'
        }), 400
    
    count = db.delete_all_scans()
    return jsonify({
        'success': True,
        'message': f'å·²æ¸…ç©º {count} æ¡è®°å½•'
    })


# å…¨å±€è¯·æ±‚é™æµå™¨
last_api_request_time = 0
API_REQUEST_INTERVAL = 1.0  # æœ€å°è¯·æ±‚é—´éš”ï¼ˆç§’ï¼‰

@app.route('/api/stock/<code>')
def get_stock_detail(code: str):
    """
    è·å–å•åªè‚¡ç¥¨è¯¦æƒ…ï¼ˆä½¿ç”¨æ–°æµªæ¥å£ï¼‰
    
    è¿”å›æŒ‡å®šè‚¡ç¥¨çš„Kçº¿æ•°æ®å’ŒæŠ€æœ¯æŒ‡æ ‡ã€‚ä¼˜å…ˆä½¿ç”¨ç¼“å­˜æ•°æ®ã€‚
    
    Args:
        code: è‚¡ç¥¨ä»£ç ï¼ˆ6ä½æ•°å­—ï¼‰
        
    Returns:
        JSON: {
            success: bool,
            data: {candles, volumes, bb_*, cmf, ...},
            cached: bool,  # æ˜¯å¦æ¥è‡ªç¼“å­˜
            error: str (ä»…å¤±è´¥æ—¶)
        }
        
    Note:
        - ç¼“å­˜æœ‰æ•ˆæœŸä¸ºå½“æ—¥
        - ä¸¤æ¬¡APIè¯·æ±‚é—´éš”è‡³å°‘1ç§’ï¼ˆé™æµä¿æŠ¤ï¼‰
    """
    global last_api_request_time
    
    from utils.ths_crawler import get_stock_kline_sina
    
    # å‚æ•°éªŒè¯
    if not code or not code.isdigit() or len(code) != 6:
        return jsonify({'success': False, 'error': 'æ— æ•ˆçš„è‚¡ç¥¨ä»£ç '})
    
    try:
        # å…ˆæ£€æŸ¥ç¼“å­˜ï¼ˆå½“æ—¥æœ‰æ•ˆï¼‰
        cached_data = db.get_kline_cache(code)
        if cached_data:
            logger.info(f"[CACHE HIT] è‚¡ç¥¨ {code} ä½¿ç”¨ç¼“å­˜æ•°æ®")
            return jsonify({'success': True, 'data': cached_data, 'cached': True})
        
        logger.info(f"[CACHE MISS] è‚¡ç¥¨ {code} ä»æ–°æµªAPIè·å–æ•°æ®")
        
        # å…¨å±€é™æµï¼šç¡®ä¿ä¸¤æ¬¡APIè°ƒç”¨ä¹‹é—´è‡³å°‘é—´éš” 1 ç§’
        current_time = time.time()
        time_since_last = current_time - last_api_request_time
        if time_since_last < API_REQUEST_INTERVAL:
            time.sleep(API_REQUEST_INTERVAL - time_since_last)
        
        last_api_request_time = time.time()
        
        # ä½¿ç”¨æ–°æµªæ¥å£è·å–Kçº¿ï¼ˆå·²åŒ…å«é‡è¯•ï¼‰
        df = get_stock_kline_sina(code, days=120)
        
        if df is None or df.empty:
            return jsonify({'success': False, 'error': 'æ•°æ®è·å–å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•'})
        
        strategy = BollingerSqueezeStrategy()
        df = strategy.calculate_bollinger_bands(df)
        df = strategy.calculate_squeeze_signal(df)
        df = strategy.calculate_trend_indicators(df)  # åŒ…å« CMF è®¡ç®—
        
        # ä½¿ç”¨å…¬å…±å‡½æ•°å‡†å¤‡Kçº¿æ•°æ®
        data = prepare_kline_data(df)
        
        if data is None:
            return jsonify({'success': False, 'error': 'æ•°æ®å¤„ç†å¤±è´¥'})
        
        # ä¿å­˜åˆ°ç¼“å­˜
        db.save_kline_cache(code, data)
        logger.info(f"[CACHE SAVE] è‚¡ç¥¨ {code} æ•°æ®å·²ç¼“å­˜")
        
        return jsonify({'success': True, 'data': data, 'cached': False})
        
    except Exception as e:
        logger.error(f"è·å–è‚¡ç¥¨ {code} è¯¦æƒ…å¤±è´¥: {e}")
        return jsonify({'success': False, 'error': str(e)})


@app.route('/api/cache/stats')
def get_cache_stats():
    """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
    try:
        stats = db.get_kline_cache_stats()
        return jsonify({'success': True, 'data': stats})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})


@app.route('/api/cache/clear', methods=['DELETE'])
def clear_cache():
    """æ¸…ç†è¿‡æœŸç¼“å­˜ï¼ˆéå½“æ—¥ï¼‰"""
    try:
        count = db.delete_expired_kline_cache()
        return jsonify({
            'success': True,
            'message': f'å·²æ¸…ç† {count} æ¡è¿‡æœŸç¼“å­˜'
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})


# ==================== è‡ªé€‰è‚¡ API ====================

@app.route('/api/watchlist')
def get_watchlist():
    """è·å–è‡ªé€‰åˆ—è¡¨"""
    try:
        stocks = db.get_watchlist()
        return jsonify({'success': True, 'data': stocks})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})


@app.route('/api/watchlist/add', methods=['POST'])
def add_to_watchlist():
    """æ·»åŠ è‚¡ç¥¨åˆ°è‡ªé€‰"""
    try:
        data = request.json
        if not data or not data.get('code') or not data.get('name'):
            return jsonify({'success': False, 'error': 'ç¼ºå°‘è‚¡ç¥¨ä»£ç æˆ–åç§°'})
        
        success = db.add_to_watchlist(
            stock_code=data['code'],
            stock_name=data['name'],
            sector_name=data.get('sector'),
            note=data.get('note')
        )
        
        if success:
            return jsonify({'success': True, 'message': 'å·²æ·»åŠ åˆ°è‡ªé€‰'})
        else:
            return jsonify({'success': False, 'error': 'æ·»åŠ å¤±è´¥'})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})


@app.route('/api/watchlist/remove', methods=['POST'])
def remove_from_watchlist():
    """ä»è‡ªé€‰ç§»é™¤è‚¡ç¥¨"""
    try:
        data = request.json
        if not data or not data.get('code'):
            return jsonify({'success': False, 'error': 'ç¼ºå°‘è‚¡ç¥¨ä»£ç '})
        
        success = db.remove_from_watchlist(data['code'])
        
        if success:
            return jsonify({'success': True, 'message': 'å·²ä»è‡ªé€‰ç§»é™¤'})
        else:
            return jsonify({'success': False, 'error': 'ç§»é™¤å¤±è´¥'})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})


@app.route('/api/watchlist/check/<code>')
def check_watchlist(code: str):
    """æ£€æŸ¥è‚¡ç¥¨æ˜¯å¦åœ¨è‡ªé€‰ä¸­"""
    try:
        in_watchlist = db.is_in_watchlist(code)
        return jsonify({'success': True, 'in_watchlist': in_watchlist})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})


@app.route('/api/watchlist/clear', methods=['DELETE'])
def clear_watchlist():
    """æ¸…ç©ºè‡ªé€‰åˆ—è¡¨"""
    try:
        count = db.clear_watchlist()
        return jsonify({
            'success': True,
            'message': f'å·²æ¸…ç©º {count} åªè‡ªé€‰è‚¡'
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})


# ==================== AI åˆ†ææ¥å£ ====================

@app.route('/api/ai/config', methods=['GET'])
def get_ai_config():
    """è·å– AI é…ç½®çŠ¶æ€"""
    ai_service = get_ai_service()
    return jsonify({
        'success': True,
        'configured': ai_service.is_configured()
    })


@app.route('/api/ai/config', methods=['POST'])
def set_ai_config():
    """è®¾ç½® AI API Key"""
    try:
        data = request.get_json()
        api_key = data.get('api_key', '')
        
        if not api_key:
            return jsonify({'success': False, 'error': 'è¯·æä¾› API Key'})
        
        # é‡æ–°åˆå§‹åŒ– AI æœåŠ¡
        ai_service = get_ai_service(api_key)
        
        return jsonify({
            'success': True,
            'configured': ai_service.is_configured()
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})


@app.route('/api/ai/analyze', methods=['POST'])
def ai_analyze():
    """AI åˆ†æè‚¡ç¥¨"""
    try:
        ai_service = get_ai_service()
        
        if not ai_service.is_configured():
            return jsonify({
                'success': False,
                'error': 'AI æœåŠ¡æœªé…ç½®'
            })
        
        # è·å–æœ€æ–°çš„æ‰«æç»“æœ
        latest_scan = db.get_latest_scan()
        
        if not latest_scan:
            return jsonify({
                'success': False,
                'error': 'æ²¡æœ‰å¯åˆ†æçš„æ‰«ææ•°æ®ï¼Œè¯·å…ˆæ‰§è¡Œæ‰«æ'
            })
        
        # å°†æ¿å—ç»“æœå±•å¹³ä¸ºè‚¡ç¥¨åˆ—è¡¨
        # results ç»“æ„: {'æ¿å—å': {'change': float, 'stocks': [...]}, ...}
        results_dict = latest_scan.get('results', {})
        all_stocks = []
        
        for sector_name, sector_data in results_dict.items():
            if isinstance(sector_data, dict):
                stocks = sector_data.get('stocks', [])
                for stock in stocks:
                    if isinstance(stock, dict):
                        stock['sector'] = sector_name  # æ·»åŠ æ¿å—ä¿¡æ¯
                        all_stocks.append(stock)
        
        if not all_stocks:
            return jsonify({
                'success': False,
                'error': 'æ‰«æç»“æœä¸ºç©ºï¼Œè¯·é‡æ–°æ‰§è¡Œæ‰«æ'
            })
        
        scan_data = {
            'results': all_stocks,
            'scan_time': latest_scan.get('scan_time', '')
        }
        
        # è·å–å½“å‰æ—¶é—´
        current_time = datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M')
        
        # æ‰§è¡Œ AI åˆ†æ
        result = ai_service.analyze_stocks(scan_data, current_time)
        
        # ä¿å­˜æŠ¥å‘Šåˆ°æ•°æ®åº“
        if result.get('success'):
            scan_id = latest_scan.get('id') if latest_scan else None
            report_id = db.save_ai_report(
                analysis=result.get('analysis', ''),
                model=result.get('model', ''),
                tokens_used=result.get('tokens_used', 0),
                scan_id=scan_id,
                scan_data_summary=f"å…±{len(all_stocks)}åªè‚¡ç¥¨"
            )
            result['report_id'] = report_id
        
        return jsonify(result)
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({'success': False, 'error': str(e)})


# ==================== AI æŠ¥å‘Šç®¡ç†æ¥å£ ====================

@app.route('/api/ai/reports')
def get_ai_reports():
    """è·å– AI æŠ¥å‘Šåˆ—è¡¨"""
    try:
        limit = request.args.get('limit', 20, type=int)
        reports = db.get_ai_reports(limit)
        
        # ç®€åŒ–è¿”å›æ•°æ®ï¼ˆåˆ—è¡¨ä¸è¿”å›å®Œæ•´åˆ†æå†…å®¹ï¼‰
        for report in reports:
            if report.get('analysis'):
                # åªè¿”å›å‰100å­—ä½œä¸ºé¢„è§ˆ
                report['preview'] = report['analysis'][:100] + '...' if len(report['analysis']) > 100 else report['analysis']
                del report['analysis']
        
        return jsonify({'success': True, 'data': reports})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})


@app.route('/api/ai/reports/<int:report_id>')
def get_ai_report(report_id: int):
    """è·å–å•ä¸ª AI æŠ¥å‘Šè¯¦æƒ…"""
    try:
        report = db.get_ai_report(report_id)
        if report:
            return jsonify({'success': True, 'data': report})
        return jsonify({'success': False, 'error': 'æŠ¥å‘Šä¸å­˜åœ¨'})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})


@app.route('/api/ai/reports/<int:report_id>', methods=['DELETE'])
def delete_ai_report(report_id: int):
    """åˆ é™¤ AI æŠ¥å‘Š"""
    try:
        if db.delete_ai_report(report_id):
            return jsonify({'success': True, 'message': 'åˆ é™¤æˆåŠŸ'})
        return jsonify({'success': False, 'error': 'æŠ¥å‘Šä¸å­˜åœ¨'})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})


@app.route('/api/ai/reports/clear', methods=['DELETE'])
def clear_ai_reports():
    """æ¸…ç©ºæ‰€æœ‰ AI æŠ¥å‘Š"""
    try:
        count = db.delete_all_ai_reports()
        return jsonify({'success': True, 'message': f'å·²åˆ é™¤ {count} æ¡æŠ¥å‘Š'})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})


if __name__ == '__main__':
    app.run(debug=False, host='0.0.0.0', port=5001)
